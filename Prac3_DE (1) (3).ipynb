{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prac 3a"
      ],
      "metadata": {
        "id": "dzO24Z3ZPPoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType, ArrayType, StructType, StructField\n",
        "spark = SparkSession.builder.appName('Examples').getOrCreate()"
      ],
      "metadata": {
        "id": "GJcl8WI0Pb-4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arraycol = ArrayType(StringType(), False)"
      ],
      "metadata": {
        "id": "zKZSSXJRPyhp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"James Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],\"OH\",\"CA\"),\n",
        "    (\"Michael Rose\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"],\"NY\",\"NJ\"),\n",
        "    ('Robert williams', ['CSharp', 'VB'], ['Spark', 'Python'], 'UT', 'NV')\n",
        "]"
      ],
      "metadata": {
        "id": "bUFKO9pLP0_Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([StructField('name', StringType(), True),\n",
        "                     StructField('languagesAtSchool', arraycol, True),\n",
        "                     StructField('languagesAtWork', arraycol, True),\n",
        "                     StructField('currentState', StringType(), True),\n",
        "                     StructField('previousState', StringType(), True)\n",
        "                     ])"
      ],
      "metadata": {
        "id": "v-WpMvccQFrA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=data, schema=schema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on69e5PNQafy",
        "outputId": "7906e478-0f5c-44e0-9867-9e80a67dc046"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- languagesAtSchool: array (nullable = true)\n",
            " |    |-- element: string (containsNull = false)\n",
            " |-- languagesAtWork: array (nullable = true)\n",
            " |    |-- element: string (containsNull = false)\n",
            " |-- currentState: string (nullable = true)\n",
            " |-- previousState: string (nullable = true)\n",
            "\n",
            "+---------------+------------------+---------------+------------+-------------+\n",
            "|           name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
            "+---------------+------------------+---------------+------------+-------------+\n",
            "|    James Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
            "|   Michael Rose|[Spark, Java, C++]|  [Spark, Java]|          NY|           NJ|\n",
            "|Robert williams|      [CSharp, VB]|[Spark, Python]|          UT|           NV|\n",
            "+---------------+------------------+---------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df.select(df.name, explode(df.languagesAtSchool)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDz_NyW4RPy4",
        "outputId": "67cb4980-cb4d-4740-ec17-87715b30d085"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------+\n",
            "|           name|   col|\n",
            "+---------------+------+\n",
            "|    James Smith|  Java|\n",
            "|    James Smith| Scala|\n",
            "|    James Smith|   C++|\n",
            "|   Michael Rose| Spark|\n",
            "|   Michael Rose|  Java|\n",
            "|   Michael Rose|   C++|\n",
            "|Robert williams|CSharp|\n",
            "|Robert williams|    VB|\n",
            "+---------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split\n",
        "df.select(split(df.name, \" \").alias('nameAsArray')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPsp9UowRzLg",
        "outputId": "e2dc9406-5dbf-4b7c-cbc8-b6699317d45c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|       nameAsArray|\n",
            "+------------------+\n",
            "|    [James, Smith]|\n",
            "|   [Michael, Rose]|\n",
            "|[Robert, williams]|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array\n",
        "df.select(df.name, array(df.currentState, df.previousState).alias(\"States\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARZOO24aSBAB",
        "outputId": "fc904aa7-92b9-4e3b-d791-079af9afe845"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------+\n",
            "|           name|  States|\n",
            "+---------------+--------+\n",
            "|    James Smith|[OH, CA]|\n",
            "|   Michael Rose|[NY, NJ]|\n",
            "|Robert williams|[UT, NV]|\n",
            "+---------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_contains\n",
        "df.select(df.name, array_contains(df.languagesAtSchool, \"Java\").alias('array_contains')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgQokZuVSlQp",
        "outputId": "4718ea99-73bb-4ce4-d03c-cf8475b1e551"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+\n",
            "|           name|array_contains|\n",
            "+---------------+--------------+\n",
            "|    James Smith|          true|\n",
            "|   Michael Rose|          true|\n",
            "|Robert williams|         false|\n",
            "+---------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "obFWE9PMS5sp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prac 3B"
      ],
      "metadata": {
        "id": "cy2ogFrXd5Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Exam').getOrCreate()"
      ],
      "metadata": {
        "id": "w68LCdmId8Dl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"name\", \"languagesAtschool\", \"CurrentState\"]\n",
        "data = [(\"James smith\", [\"Java\", \"Scala\", \"C++\"], \"CA\"),\n",
        "        (\"Michaeal Rose\", [\"Spark\", \"Java\", \"C++\"], \"NJ\"),\n",
        "        (\"Robert Williams\", [\"CSharp\", \"VB\"], \"NV\")]"
      ],
      "metadata": {
        "id": "Jyce1HwleFDm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=data, schema=columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty_m_0ObeW7d",
        "outputId": "62d51231-2438-4cf2-b923-642e5f098b01"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- languagesAtschool: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- CurrentState: string (nullable = true)\n",
            "\n",
            "+---------------+------------------+------------+\n",
            "|name           |languagesAtschool |CurrentState|\n",
            "+---------------+------------------+------------+\n",
            "|James smith    |[Java, Scala, C++]|CA          |\n",
            "|Michaeal Rose  |[Spark, Java, C++]|NJ          |\n",
            "|Robert Williams|[CSharp, VB]      |NV          |\n",
            "+---------------+------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, concat_ws\n",
        "df2 = df.withColumn(\"languagesAtschool\", concat_ws(\",\", col(\"languagesAtSchool\")))\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFSaJqZme0H8",
        "outputId": "b4aeb2d4-f563-4375-e5ea-aee25183c727"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- languagesAtschool: string (nullable = false)\n",
            " |-- CurrentState: string (nullable = true)\n",
            "\n",
            "+---------------+-----------------+------------+\n",
            "|name           |languagesAtschool|CurrentState|\n",
            "+---------------+-----------------+------------+\n",
            "|James smith    |Java,Scala,C++   |CA          |\n",
            "|Michaeal Rose  |Spark,Java,C++   |NJ          |\n",
            "|Robert Williams|CSharp,VB        |NV          |\n",
            "+---------------+-----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"ARRAY_STRING\")\n",
        "spark.sql(\"select name,concat_ws(',',languagesAtSchool) as languagesAtSchool,currentstate from ARRAY_STRING\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBx8VWobghlM",
        "outputId": "47eb57a5-1970-4216-eb81-4825f502cac2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------------+------------+\n",
            "|name           |languagesAtSchool|currentstate|\n",
            "+---------------+-----------------+------------+\n",
            "|James smith    |Java,Scala,C++   |CA          |\n",
            "|Michaeal Rose  |Spark,Java,C++   |NJ          |\n",
            "|Robert Williams|CSharp,VB        |NV          |\n",
            "+---------------+-----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prac 3C"
      ],
      "metadata": {
        "id": "xuu4ooqbhXuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Exam\").getOrCreate()"
      ],
      "metadata": {
        "id": "cPfafL9whZuU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = ['Project',\n",
        "        \"Gutenberg's\",\n",
        "        \"Alice's\",\n",
        "        \"Adventures\",\n",
        "        \"in\",\n",
        "        \"Wonderland\",\n",
        "        \"Project\",\n",
        "        \"Gutenberg's\",\n",
        "        \"Adventures\",\n",
        "        \"in\",\n",
        "        \"Wonderland\",\n",
        "        \"Project\",\n",
        "        \"Gutenberg's\"]"
      ],
      "metadata": {
        "id": "Vnin0m2Uhiz7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize(data)"
      ],
      "metadata": {
        "id": "DZfjxYBNiXoa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2 = rdd.map(lambda x:(x,1))\n",
        "for element in rdd2.collect():\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-CwK6yBibIi",
        "outputId": "2174f222-5639-4cb5-97fc-e7f292c1a49f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Project', 1)\n",
            "(\"Gutenberg's\", 1)\n",
            "(\"Alice's\", 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "(\"Gutenberg's\", 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "(\"Gutenberg's\", 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [('James', 'Smith', 'M', 30),\n",
        "        (\"Anna\", \"Rose\", \"F\", 41),\n",
        "        (\"Robert\", \"Williams\", \"M\", 62)]"
      ],
      "metadata": {
        "id": "cybbxKkLiiOK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"firstname\", \"lastname\", \"gender\", \"salary\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQSj2XHQi_OK",
        "outputId": "2fb82e6a-3012-42da-d953-14c3696a6e83"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------+------+\n",
            "|firstname|lastname|gender|salary|\n",
            "+---------+--------+------+------+\n",
            "|    James|   Smith|     M|    30|\n",
            "|     Anna|    Rose|     F|    41|\n",
            "|   Robert|Williams|     M|    62|\n",
            "+---------+--------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2 = df.rdd.map(lambda x:\n",
        "                  (x[0]+\",\"+x[1], x[2], x[3]*2))\n",
        "\n",
        "df2 = rdd2.toDF([\"name\", \"gender\", \"new_salary\"])\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUli9v5AjJSS",
        "outputId": "abb3bb88-d27d-44e4-c761-3e603ef59c6a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------+----------+\n",
            "|           name|gender|new_salary|\n",
            "+---------------+------+----------+\n",
            "|    James,Smith|     M|        60|\n",
            "|      Anna,Rose|     F|        82|\n",
            "|Robert,Williams|     M|       124|\n",
            "+---------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Referring column Names\n",
        "rdd2 = df.rdd.map(lambda x:\n",
        "                  (x['firstname'] + \",\" + x[\"lastname\"], x[\"gender\"], x[\"salary\"]*2))"
      ],
      "metadata": {
        "id": "P9Kj682HkRIR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Referring column Names\n",
        "rdd2 = df.rdd.map(lambda x:\n",
        "                  (x.firstname + \",\" + x.lastname, x.gender, x.salary*2))"
      ],
      "metadata": {
        "id": "ek0Z5vyCkmwJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func1(x):\n",
        "  firstName = x.firstname\n",
        "  lastName = x.lastname\n",
        "  name = firstName + \",\" + lastName\n",
        "  gender = x.gender.lower()\n",
        "  salary = x.salary*2\n",
        "  return (name, gender, salary)"
      ],
      "metadata": {
        "id": "HDdhrjValAPB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2 = df.rdd.map(lambda x: func1(x))"
      ],
      "metadata": {
        "id": "Kxy8D3jEllJg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prac D"
      ],
      "metadata": {
        "id": "Mk8M_pGemODQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Exam\").getOrCreate()"
      ],
      "metadata": {
        "id": "nt-qt27KmRE4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataDictionary = [\n",
        "    ('James', {'hair':'black', 'eye':'brown'}),\n",
        "    ('Michael', {'hair':'brown', 'eye':None}),\n",
        "    ('Robert', {'hair':'red', 'eye':'black'}),\n",
        "    ('Washington', {'hair':'grey', 'eye':'grey'}),\n",
        "    ('Jefferson', {'hair':'brown', 'eye':''})\n",
        "]"
      ],
      "metadata": {
        "id": "UXGAzb_ombVY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=dataDictionary, schema=['name', 'properties'])\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waILHCG_mqmI",
        "outputId": "0d626cea-38a8-48c7-f127-3e2000d533ee"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+----------+-----------------------------+\n",
            "|name      |properties                   |\n",
            "+----------+-----------------------------+\n",
            "|James     |{eye -> brown, hair -> black}|\n",
            "|Michael   |{eye -> NULL, hair -> brown} |\n",
            "|Robert    |{eye -> black, hair -> red}  |\n",
            "|Washington|{eye -> grey, hair -> grey}  |\n",
            "|Jefferson |{eye -> , hair -> brown}     |\n",
            "+----------+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df.rdd.map(lambda x: (x.name, x.properties['hair'], x.properties['eye'])).toDF(['name', 'hair', 'eye'])\n",
        "df3.printSchema()\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcTrRPkymuDY",
        "outputId": "1975fb73-e9f8-4dc5-fe04-316999b877b2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- hair: string (nullable = true)\n",
            " |-- eye: string (nullable = true)\n",
            "\n",
            "+----------+-----+-----+\n",
            "|      name| hair|  eye|\n",
            "+----------+-----+-----+\n",
            "|     James|black|brown|\n",
            "|   Michael|brown| NULL|\n",
            "|    Robert|  red|black|\n",
            "|Washington| grey| grey|\n",
            "| Jefferson|brown|     |\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"hair\", df.properties.getItem(\"hair\"))\\\n",
        "  .withColumn(\"eye\", df.properties.getItem(\"eye\"))\\\n",
        "  .drop(\"properties\")\\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YkPo0Funs__",
        "outputId": "c1e7816f-0807-4d4c-85a9-6e33dee89e2a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+\n",
            "|      name| hair|  eye|\n",
            "+----------+-----+-----+\n",
            "|     James|black|brown|\n",
            "|   Michael|brown| NULL|\n",
            "|    Robert|  red|black|\n",
            "|Washington| grey| grey|\n",
            "| Jefferson|brown|     |\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"hair\", df.properties[\"hair\"])\\\n",
        "  .withColumn(\"eye\", df.properties[\"eye\"])\\\n",
        "  .drop(\"properties\")\\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4p5AYxQoHg3",
        "outputId": "76b89325-222e-4dba-bb89-77d69d61c34f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+\n",
            "|      name| hair|  eye|\n",
            "+----------+-----+-----+\n",
            "|     James|black|brown|\n",
            "|   Michael|brown| NULL|\n",
            "|    Robert|  red|black|\n",
            "|Washington| grey| grey|\n",
            "| Jefferson|brown|     |\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# functions\n",
        "from pyspark.sql.functions import explode, map_keys, col\n",
        "keysDF = df.select(explode(map_keys(df.properties))).distinct()\n",
        "keysList = keysDF.rdd.map(lambda x: x[0]).collect()\n",
        "keyCols = list(map(lambda x: col(\"properties\").getItem(x).alias(str(x)), keysList))"
      ],
      "metadata": {
        "id": "FNvbK8KWopX_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.name, *keyCols).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WONDir_o6eW",
        "outputId": "b7deba43-e99d-4c38-e8df-cac122b7f402"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----+\n",
            "|      name|  eye| hair|\n",
            "+----------+-----+-----+\n",
            "|     James|brown|black|\n",
            "|   Michael| NULL|brown|\n",
            "|    Robert|black|  red|\n",
            "|Washington| grey| grey|\n",
            "| Jefferson|     |brown|\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prac E"
      ],
      "metadata": {
        "id": "ipYp_nWpqBLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('pyspark-by-example').getOrCreate()"
      ],
      "metadata": {
        "id": "vD07ADz5qDfO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arrayData = [\n",
        "    ('James', ['Java', \"Scala\"], {'hair':'black', 'eye':'brows'}),\n",
        "    ('Michael', ['Spark', 'Java', None], {'hair':'brown', 'eye':None}),\n",
        "    ('Robert', ['CSharp', \"\"], {'hair':'red', 'eye':''}),\n",
        "    ('Washington', None, None),\n",
        "    ('Jefferson', ['1', '2'], {})\n",
        "]"
      ],
      "metadata": {
        "id": "MnGTSFfoqT4d"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data=arrayData, schema=['name', 'knownLanguages', 'properties'])\n",
        "df.show()"
      ],
      "metadata": {
        "id": "hQHM5i-sq911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787c9c80-ca87-4a46-c2a1-962a65079a01"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+--------------------+\n",
            "|      name|     knownLanguages|          properties|\n",
            "+----------+-------------------+--------------------+\n",
            "|     James|      [Java, Scala]|{eye -> brows, ha...|\n",
            "|   Michael|[Spark, Java, NULL]|{eye -> NULL, hai...|\n",
            "|    Robert|         [CSharp, ]|{eye -> , hair ->...|\n",
            "|Washington|               NULL|                NULL|\n",
            "| Jefferson|             [1, 2]|                  {}|\n",
            "+----------+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df2 = df.select(df.name, explode(df.knownLanguages))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "id": "SW90pqHgrBkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe8f905-6fb5-4032-8fb6-9d48034ada47"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+---------+------+\n",
            "|     name|   col|\n",
            "+---------+------+\n",
            "|    James|  Java|\n",
            "|    James| Scala|\n",
            "|  Michael| Spark|\n",
            "|  Michael|  Java|\n",
            "|  Michael|  NULL|\n",
            "|   Robert|CSharp|\n",
            "|   Robert|      |\n",
            "|Jefferson|     1|\n",
            "|Jefferson|     2|\n",
            "+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df3 = df.select(df.name, explode(df.properties))\n",
        "df3.printSchema()\n",
        "df3.show()"
      ],
      "metadata": {
        "id": "BG2xq1jQsKtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7496f2ad-e594-49e6-8109-c9dac1633c90"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- key: string (nullable = false)\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "+-------+----+-----+\n",
            "|   name| key|value|\n",
            "+-------+----+-----+\n",
            "|  James| eye|brows|\n",
            "|  James|hair|black|\n",
            "|Michael| eye| NULL|\n",
            "|Michael|hair|brown|\n",
            "| Robert| eye|     |\n",
            "| Robert|hair|  red|\n",
            "+-------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode_outer\n",
        "\"\"\"with array\"\"\"\n",
        "df.select(df.name, explode_outer(df.knownLanguages)).show()\n",
        "\"\"\"with map\"\"\"\n",
        "df.select(df.name, explode_outer(df.properties)).show()\n"
      ],
      "metadata": {
        "id": "PnBvNNgYsWO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9360701f-24bc-483c-c04a-38e6c1c0e67f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+\n",
            "|      name|   col|\n",
            "+----------+------+\n",
            "|     James|  Java|\n",
            "|     James| Scala|\n",
            "|   Michael| Spark|\n",
            "|   Michael|  Java|\n",
            "|   Michael|  NULL|\n",
            "|    Robert|CSharp|\n",
            "|    Robert|      |\n",
            "|Washington|  NULL|\n",
            "| Jefferson|     1|\n",
            "| Jefferson|     2|\n",
            "+----------+------+\n",
            "\n",
            "+----------+----+-----+\n",
            "|      name| key|value|\n",
            "+----------+----+-----+\n",
            "|     James| eye|brows|\n",
            "|     James|hair|black|\n",
            "|   Michael| eye| NULL|\n",
            "|   Michael|hair|brown|\n",
            "|    Robert| eye|     |\n",
            "|    Robert|hair|  red|\n",
            "|Washington|NULL| NULL|\n",
            "| Jefferson|NULL| NULL|\n",
            "+----------+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import posexplode\n",
        "\"\"\"with array\"\"\"\n",
        "df.select(df.name, posexplode(df.knownLanguages)).show()\n",
        "\"\"\"with map\"\"\"\n",
        "df.select(df.name, posexplode(df.properties)).show()"
      ],
      "metadata": {
        "id": "5CuUrH9Msa3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06cf432d-be67-4c30-8d1f-9edd81f2e9e1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+------+\n",
            "|     name|pos|   col|\n",
            "+---------+---+------+\n",
            "|    James|  0|  Java|\n",
            "|    James|  1| Scala|\n",
            "|  Michael|  0| Spark|\n",
            "|  Michael|  1|  Java|\n",
            "|  Michael|  2|  NULL|\n",
            "|   Robert|  0|CSharp|\n",
            "|   Robert|  1|      |\n",
            "|Jefferson|  0|     1|\n",
            "|Jefferson|  1|     2|\n",
            "+---------+---+------+\n",
            "\n",
            "+-------+---+----+-----+\n",
            "|   name|pos| key|value|\n",
            "+-------+---+----+-----+\n",
            "|  James|  0| eye|brows|\n",
            "|  James|  1|hair|black|\n",
            "|Michael|  0| eye| NULL|\n",
            "|Michael|  1|hair|brown|\n",
            "| Robert|  0| eye|     |\n",
            "| Robert|  1|hair|  red|\n",
            "+-------+---+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import posexplode_outer\n",
        "\"\"\"with array\"\"\"\n",
        "df.select(df.name, posexplode_outer(df.knownLanguages)).show()\n",
        "\n",
        "\"\"\"with map\"\"\"\n",
        "df.select(df.name, posexplode_outer(df.properties)).show()\n"
      ],
      "metadata": {
        "id": "D1fGFrCsti9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e912c2a-96c0-4ac1-8a5b-f354df252fde"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+\n",
            "|      name| pos|   col|\n",
            "+----------+----+------+\n",
            "|     James|   0|  Java|\n",
            "|     James|   1| Scala|\n",
            "|   Michael|   0| Spark|\n",
            "|   Michael|   1|  Java|\n",
            "|   Michael|   2|  NULL|\n",
            "|    Robert|   0|CSharp|\n",
            "|    Robert|   1|      |\n",
            "|Washington|NULL|  NULL|\n",
            "| Jefferson|   0|     1|\n",
            "| Jefferson|   1|     2|\n",
            "+----------+----+------+\n",
            "\n",
            "+----------+----+----+-----+\n",
            "|      name| pos| key|value|\n",
            "+----------+----+----+-----+\n",
            "|     James|   0| eye|brows|\n",
            "|     James|   1|hair|black|\n",
            "|   Michael|   0| eye| NULL|\n",
            "|   Michael|   1|hair|brown|\n",
            "|    Robert|   0| eye|     |\n",
            "|    Robert|   1|hair|  red|\n",
            "|Washington|NULL|NULL| NULL|\n",
            "| Jefferson|NULL|NULL| NULL|\n",
            "+----------+----+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prac F"
      ],
      "metadata": {
        "id": "yJqp9tbAuzAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode,flatten"
      ],
      "metadata": {
        "id": "UbG1CvTYjK0G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('pyspark-by-examples').getOrCreate()"
      ],
      "metadata": {
        "id": "kF0a93UejNwD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arrayArrayData = [\n",
        "    (\"James\", [['Java', 'Scala', 'C++'], [\"Spark\", \"Java\"]]),\n",
        "    (\"Michael\", [[\"Spark\", \"Java\", \"C++\"], [\"Spark\", \"Java\"]]),\n",
        "    (\"Robert\", [[\"CSharp\", \"VB\"], [\"Spark\", \"Python\"]])  # FIXED\n",
        "]\n"
      ],
      "metadata": {
        "id": "L6qnba3ijPTf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(data = arrayArrayData, schema = ['name', 'subjects'])\n",
        "df.printSchema()\n",
        "df.show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLtIC6OojTxG",
        "outputId": "41fe7aed-3427-422d-d01d-2e7213839614"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- subjects: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------+-----------------------------------+\n",
            "|name   |subjects                           |\n",
            "+-------+-----------------------------------+\n",
            "|James  |[[Java, Scala, C++], [Spark, Java]]|\n",
            "|Michael|[[Spark, Java, C++], [Spark, Java]]|\n",
            "|Robert |[[CSharp, VB], [Spark, Python]]    |\n",
            "+-------+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.name, explode(df.subjects)).show(truncate = False)\n",
        "\n",
        "\n",
        "\"\"\"create a single array from an array of arrays\"\"\"\n",
        "\n",
        "df.select(df.name, flatten(df.subjects)).show(truncate=False)"
      ],
      "metadata": {
        "id": "oT4Umt8hvylq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}